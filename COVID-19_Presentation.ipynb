{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Johns Hopkins University's Data Vizualization of COVID-19\n",
    "\n",
    "READ: In accordance with JHU's statement on the fitness of this data for medical purposes, I also prohibit the use of this notebook for any medical purpose. \"Reliance on the Website for medical guidance or use of the Website in commerce is strictly prohibited.\" --https://coronavirus.jhu.edu/map.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "\n",
    "When our team decides to develop an ML product, we think about the available data we have to train the models that will make up the product and the \"use case\". Stakeholders who are close to our clients' needs will frame a use case like this: \"_As a user, I want to_ [see a dashboard/receive an alert/run an automation] _that_ [tells me something about my system/takes some action on my system]\". Then, it is our job as the AI/ML team to figure out what type of model(s) would solve that problem and whether the data provided by the client would work with such a model. \n",
    "\n",
    "Today, we will evaluate Johns Hopkins University's data on COVID-19 (which they've made available on GitHub: https://github.com/CSSEGISandData/COVID-19). The dashboard is super awesome! What if we want to add a comparison between the death rates? This tutorial will calculate the death rate per country given the number of daily confirmed cases and deaths, and explore options for timeseries analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning Objectives: \n",
    "\n",
    "- Understand the concept of a \"use case\" or \"business case\" for creating a data product in a business setting. \n",
    "- Learn to see beyond the dashboard to answer more in-depth questions.\n",
    "- Reinforce basic pandas library for data manipulation\n",
    "- Introduction to timeseries concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some csv files from JHU's COVID-19 GitHub Repo:\n",
    "\n",
    "jhu_csv_confirmed = '../COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv'\n",
    "jhu_csv_deaths = '../COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv'\n",
    "jhu_csv_recovered = '../COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv'\n",
    "\n",
    "jhu_last_daily_report = \"../COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/03-21-2020.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in CSVs as a dataframes\n",
    "covid_confirmed_df = pd.read_csv(jhu_csv_confirmed) \n",
    "covid_deaths_df = pd.read_csv(jhu_csv_deaths) \n",
    "covid_recovered_df = pd.read_csv(jhu_csv_recovered) \n",
    "\n",
    "last_daily_report_df = pd.read_csv(jhu_last_daily_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the timeseries dataframes have the same number of geographical areas and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of Province/States: {}\".format(len(covid_confirmed_df)))\n",
    "print(\"Number of Countries: {}\".format(len(covid_confirmed_df[\"Country/Region\"].unique())))\n",
    "print(\"Number of Columns: {}\".format(len(covid_confirmed_df.columns)))\n",
    "\n",
    "covid_confirmed_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of Province/States: {}\".format(len(covid_deaths_df)))\n",
    "print(\"Number of Countries: {}\".format(len(covid_deaths_df[\"Country/Region\"].unique())))\n",
    "print(\"Number of Columns: {}\".format(len(covid_deaths_df.columns)))\n",
    "\n",
    "covid_deaths_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of Province/States: {}\".format(len(covid_recovered_df)))\n",
    "print(\"Number of Countries: {}\".format(len(covid_recovered_df[\"Country/Region\"].unique())))\n",
    "print(\"Number of Columns: {}\".format(len(covid_recovered_df.columns)))\n",
    "\n",
    "covid_recovered_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the number of geographical areas for the daily report\n",
    "\n",
    "Note that this report consolidates the Confirmed and Recovered cases and Deaths in one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of Province/States: {}\".format(len(last_daily_report_df)))\n",
    "print(\"Number of Countries: {}\".format(len(last_daily_report_df[\"Country/Region\"].unique())))\n",
    "\n",
    "last_daily_report_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \"Cleaning\"\n",
    "\n",
    "This data is already quite clean, and it is even more managable because we are working by country. We are not so much \"cleaning\" the data (such as correcting errors), as we are _reshaping_ it for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirmed Cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we want country data, so we won't be needing \"Province/State\":\n",
    "confirmed_by_country_df = covid_confirmed_df.drop(['Province/State'], axis=1)\n",
    "# we want all the cases of each country consolidated to one value, or the sum of the provinces, grouped by 'Country/Region':\n",
    "confirmed_by_country_df = covid_confirmed_df.groupby(covid_confirmed_df['Country/Region']).sum()\n",
    "# we will not need the latitude and longitude, either, as we are not going to create maps:\n",
    "confirmed_by_country_df = confirmed_by_country_df.drop(['Long', 'Lat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You may notice we simply re-stated the name the df as we made changes. \n",
    "# This is a quick way to change the df \"in-place\", but be careful to order your changes correctly! \n",
    "\n",
    "confirmed_by_country_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To prepare for a timeseries viz, a fast way to use the built-in pandas technique which uses a datetime index\n",
    "\n",
    "# transpose the dataframe:\n",
    "confirmed_by_country_datetime_df = confirmed_by_country_df.T\n",
    "# Now, it LOOKS like the index is in datetime, but:\n",
    "print(type(confirmed_by_country_datetime_df.index[0]))\n",
    "# we need to convert the data type, which is easy with pandas' to_datetime() method:\n",
    "confirmed_by_country_datetime_df.index = pd.to_datetime(confirmed_by_country_datetime_df.index)\n",
    "# now we're ready to take a look.\n",
    "confirmed_by_country_datetime_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When we transposed the dataframe, the dates that were once columns have now become the index! If you want to get a normal index at this point (and keep the Date column), you can use this code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confirmed_by_country_datetime_df[\"Date\"] = confirmed_by_country_datetime_df.index\n",
    "#confirmed_by_country_datetime_df.index = range(len(confirmed_by_country_datetime_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Deaths: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we want country data, so we won't be needing \"Province/State\":\n",
    "deaths_by_country_df = covid_deaths_df.drop(['Province/State'], axis=1)\n",
    "# we want all the cases of each country consolidated to one value, or the sum of the provinces, grouped by 'Country/Region':\n",
    "deaths_by_country_df = covid_deaths_df.groupby(covid_deaths_df['Country/Region']).sum()\n",
    "# we will not need the latitude and longitude, either, as we are not going to create maps:\n",
    "deaths_by_country_df = deaths_by_country_df.drop(['Long', 'Lat'], axis=1)\n",
    "\n",
    "deaths_by_country_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transpose the dataframe:\n",
    "deaths_by_country_datetime_df = deaths_by_country_df.T\n",
    "# we need to convert the data type, which is easy with pandas' to_datetime() method:\n",
    "deaths_by_country_datetime_df.index = pd.to_datetime(deaths_by_country_datetime_df.index)\n",
    "# now we're ready to take a look.\n",
    "deaths_by_country_datetime_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovered cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we want country data, so we won't be needing \"Province/State\":\n",
    "recovered_by_country_df = covid_recovered_df.drop(['Province/State'], axis=1)\n",
    "# we want all the cases of each country consolidated to one value, or the sum of the provinces, grouped by 'Country/Region':\n",
    "recovered_by_country_df = covid_recovered_df.groupby(covid_recovered_df['Country/Region']).sum()\n",
    "# we will not need the latitude and longitude, either, as we are not going to create maps:\n",
    "recovered_by_country_df = recovered_by_country_df.drop(['Long', 'Lat'], axis=1)\n",
    "\n",
    "recovered_by_country_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transpose the dataframe:\n",
    "recovered_by_country_datetime_df = recovered_by_country_df.T\n",
    "# we need to convert the data type, which is easy with pandas' to_datetime() method:\n",
    "recovered_by_country_datetime_df.index = pd.to_datetime(recovered_by_country_datetime_df.index)\n",
    "# now we're ready to take a look.\n",
    "recovered_by_country_datetime_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Daily Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we want country data, so we won't be needing \"Province/State\":\n",
    "last_daily_report_df = last_daily_report_df.drop(['Province/State'], axis=1)\n",
    "# we want all the cases of each country consolidated to one value, or the sum of the provinces, grouped by 'Country/Region':\n",
    "last_daily_report_df = last_daily_report_df.groupby(last_daily_report_df['Country/Region']).sum()\n",
    "# we will not need the latitude and longitude, either, as we are not going to create maps:\n",
    "last_daily_report_df = last_daily_report_df.drop(['Longitude', 'Latitude'], axis=1)\n",
    "\n",
    "last_daily_report_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the death rate\n",
    "\n",
    "One very interesting problem I have seen is the difficulty in understanding the apparent differences in death rates in different geographical areas. There are a LOT of theories out there, but as data scientists and data analysts, we just want to look at what the data tells us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can perform operations on the columns to calculate the rates: \n",
    "last_daily_report_df['Death_Rate'] = last_daily_report_df['Deaths']/last_daily_report_df['Confirmed']\n",
    "last_daily_report_df['Recovery_Rate'] = last_daily_report_df['Recovered']/last_daily_report_df['Confirmed']\n",
    "\n",
    "last_daily_report_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Viz Fun Time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "death_recovery_country_comparison_df = last_daily_report_df.T\n",
    "\n",
    "death_recovery_country_comparison_df[['New Zealand', 'US', 'China', 'Italy', 'Spain']].plot.bar()\n",
    "# China skews the figure a bit\n",
    "death_recovery_country_comparison_df[['New Zealand', 'US', 'Italy', 'Spain']].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rate_comparisons_by_country_df = last_daily_report_df[[\"Death_Rate\", \"Recovery_Rate\"]].T\n",
    "\n",
    "rate_comparisons_by_country_df[['Korea, South', 'US', 'Italy', 'Spain']].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we have a lot of countries, so if we throw them all at the visualization, it will look messy: \n",
    "\n",
    "confirmed_by_country_datetime_df.resample('D').sum().plot()\n",
    "\n",
    "# EWWW! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at the most severely hit countries and the least severely hit\n",
    "\n",
    "Remember, the timeseries dataframes are cumulative counts, so the last date (row) in the dataframe is all we need to find our target countries. Also (BONUS!) we get to learn how to use a datetime dataframe index! \n",
    "\n",
    "Another way is to take the Confirmed column from the last_daily_report, but we're going to pretend we only have the timeseries.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index the last date:\n",
    "last_row = confirmed_by_country_datetime_df.loc[datetime(2020, 3, 21)]\n",
    "# now sort it using pandas' sort_values(). The axis defaults to row, but I add it, anyway:\n",
    "sorted_last_row = last_row.sort_values(axis=0)\n",
    "# now, we have a good sample of the least and hardest hit countries. \n",
    "sorted_last_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to select some countries with more than one case, just to make the data viz more interesting, with the caveat that (of course) we are showing _\"lesser\"_ impacted countries, not _\"least\"_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's check out the middle a bit to see if there's any good stuff in there:\n",
    "sorted_last_row[45:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I'm interested in the 10 countries up to and including New Zealand. Let's check out New Zealand specifically:\n",
    "print(\"New Zealand confirmed cases: {}\".format(sorted_last_row[\"New Zealand\"]))\n",
    "# but how do I get the rest of them? The index of this series is made of strings!\n",
    "\n",
    "# make country a column in a df, and add a numerical index:\n",
    "last_row_df = sorted_last_row.to_frame()\n",
    "last_row_df[\"Country\"] = sorted_last_row.index\n",
    "last_row_df.index = range(len(last_row_df.index))\n",
    "last_row_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find New Zealand again:\n",
    "last_row_df[last_row_df[\"Country\"] == \"New Zealand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and subtract from the index number and then slice it again:\n",
    "lesser_impacted = last_row_df[66:75]\n",
    "lesser_impacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now, let's just slice off the top:\n",
    "most_impacted = last_row_df[-9:]\n",
    "most_impacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these Country columns as lists to query the larger timeseries dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lesser_impacted_list = [country for country in lesser_impacted[\"Country\"]]\n",
    "most_impacted_list = [country for country in most_impacted[\"Country\"]]\n",
    "lesser_impacted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lesser_impacted_confirmed_df = confirmed_by_country_datetime_df[lesser_impacted_list]\n",
    "lesser_impacted_deaths_df = deaths_by_country_datetime_df[lesser_impacted_list]\n",
    "lesser_impacted_deaths_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_impacted_confirmed_df = confirmed_by_country_datetime_df[most_impacted_list]\n",
    "most_impacted_deaths_df = deaths_by_country_datetime_df[most_impacted_list]\n",
    "most_impacted_confirmed_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's try those visualizations again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lesser_impacted_confirmed_df.resample('D').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_impacted_confirmed_df.resample('D').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Remember that your stakeholders have been looking forward to your analysis/results all day (or more!). The vizualizations are the part they've been waiting for most of all! So, go on, grab a few extra bells and whistles to make it more appealing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['dark_background'])\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lesser_impacted_deaths_df.plot(figsize=(15, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use(['ggplot'])\n",
    "\n",
    "most_impacted_deaths_df.plot(figsize=(15, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Study and More Questions: \n",
    "\n",
    "- Does the recovery rate contribute to the outcomes for the country? \n",
    "- What is the shape of the death rate over time?\n",
    "- Can we compare daily changes?\n",
    "- What kinds of models can we build on top of these findings? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sources: \n",
    "\n",
    "- https://coronavirus.jhu.edu/map.html\n",
    "- https://www.jstor.org/stable/2352662?read-now=1&seq=16#page_scan_tab_contents\n",
    "- https://github.com/CSSEGISandData/COVID-19\n",
    "- https://hbr.org/1971/07/how-to-choose-the-right-forecasting-technique\n",
    "- https://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "- https://matplotlib.org/tutorials/introductory/customizing.html#sphx-glr-tutorials-introductory-customizing-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE COMODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science in the field often requires finding out what useful questions can be answered with a dataset _as it is_ rather than a dataset we as professionals would like to have. For instance, I'd like to re-create the \"Titanic problem\" from Kaggle by calculating the probabilty of death given their country's case history and number of tests currently available. (If you haven't done so yet, familiarize yourself with Kaggle datasets. There are even great datasets on COVID-19, including this one from from South Korea: https://www.kaggle.com/kimjihoo/coronavirusdataset!) The data I was able to find for this tutorial, however, wouldn't be sufficient to build such a model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If I want it indexed by datetime:\n",
    "\n",
    "# confirmed_by_country_datetime_df = confirmed_by_country_df.T\n",
    "# confirmed_by_country_datetime_df.columns\n",
    "# print(type(confirmed_by_country_datetime_df.index[0]))\n",
    "\n",
    "# confirmed_by_country_datetime_df[datetime(2020, 3, 20):]\n",
    "\n",
    "# clipped_series = confirmed_by_country_datetime_df['Afghanistan'][datetime(2020, 3, 20):]\n",
    "# clipped_series.index\n",
    "\n",
    "# confirmed_by_country_datetime_df.resample('D').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If I want to predict the death rate by the incubation period:\n",
    "\n",
    "# def country_first_2_weeks(df, country):\n",
    "#     first_2_weeks_list = []\n",
    "#     for value in df[country]:\n",
    "#         if value > 0:\n",
    "#             first_2_weeks_list.append(value)\n",
    "#     return first_2_weeks_list[:14]\n",
    "\n",
    "# country_first_2_weeks(confirmed_by_country_datetime_df, \"China\")\n",
    "\n",
    "# def country_first_2_weeks(df):\n",
    "# first_2_weeks_list = []\n",
    "\n",
    "# for i, j in confirmed_by_country_df[:10].iterrows():\n",
    "#     print (i, j[0:3][0])\n",
    "    \n",
    "#     if value > 0:\n",
    "#         print(value)\n",
    "\n",
    "# for i, j in confirmed_by_country_datetime_df[50:].iterrows(): \n",
    "#     print(i ,j[0:1]) \n",
    "# country_from_first_confirmed_dict = {}\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
