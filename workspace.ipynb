{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import kmapper\n",
    "from sklearn import datasets\n",
    "from datetime import date, timedelta, datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "import networkx as nx\n",
    "import IPython\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"csse_covid_19_data/csse_covid_19_daily_reports/\")\n",
    "\n",
    "# make days array based on inputs\n",
    "pandemic_start = date(2020, 1, 22)\n",
    "\n",
    "# don't do 3-21 or earlier\n",
    "start_date = date(2020, 3, 22)\n",
    "end_date = date(2020, 6, 19)\n",
    "\n",
    "delete_location = True\n",
    "delete_unassigned = True\n",
    "normalize_data = True\n",
    "\n",
    "delta = end_date - start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(delta.days + 1):\n",
    "    # get the day\n",
    "    date = start_date + timedelta(days=day)\n",
    "    # convert to string/file name\n",
    "    day_file = date.strftime(\"%m-%d-%Y\") + \".csv\"\n",
    "\n",
    "    file_to_open = data_folder / day_file\n",
    "    raw_data = pd.read_csv(file_to_open, header=0, delimiter=',', encoding=None, usecols=(\n",
    "        \"Admin2\", \"Province_State\", \"Country_Region\", \"Lat\", \"Long_\", \"Confirmed\"))\n",
    "\n",
    "    # calculating days since covid hit US\n",
    "    days_since_start = date - pandemic_start\n",
    "\n",
    "    # adding another column with days since covid hit the US\n",
    "    raw_data['Days since start'] = days_since_start.days  # number of days\n",
    "    raw_data['Date'] = date.strftime(\"%m-%d-%Y\")\n",
    "    raw_data = raw_data.dropna()  # be careful b/c maybe too early\n",
    "    np_raw_data = raw_data.to_numpy()\n",
    "\n",
    "    rows_to_delete = []\n",
    "\n",
    "    counter = 0\n",
    "    for i in np_raw_data:\n",
    "        if i[2] != \"US\":  # hardcoded index for checking state\n",
    "            rows_to_delete.append(counter)\n",
    "        else:\n",
    "            if delete_unassigned:  # delete unassigned row if need be\n",
    "                if i[0] == \"Unassigned\":  # hardcoded index for checking county\n",
    "                    rows_to_delete.append(counter)\n",
    "                elif \"Out of\" in str(i[0]):\n",
    "                    rows_to_delete.append(counter)\n",
    "        counter = counter + 1\n",
    "\n",
    "    if day == 0:\n",
    "        # 0 refers to deleting the rows\n",
    "        final_array = np.delete(np_raw_data, rows_to_delete, 0)\n",
    "    else:\n",
    "        # 0 refers to deleting the rows\n",
    "        selected_data = np.delete(np_raw_data, rows_to_delete, 0)\n",
    "        final_array = np.vstack((final_array, selected_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New York City, New York, 03-22-2020' 'Nassau, New York, 03-22-2020'\n",
      " 'Westchester, New York, 03-22-2020' ... 'nan, Puerto Rico, 06-19-2020'\n",
      " 'nan, Recovered, 06-19-2020' 'nan, Virgin Islands, 06-19-2020']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-851c06fca6fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tda/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tda/venv/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1708\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'%d' is not a supported axis\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m     X = check_array(X, accept_sparse=sparse_format, copy=copy,\n\u001b[0m\u001b[1;32m   1711\u001b[0m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[1;32m   1712\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tda/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tda/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tda/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "if delete_location:\n",
    "    #matrix: \"Admin2\", \"Province_State\", \"Country_Region\", \"Lat\", \"Long_\", \"Confirmed\", \"days since start\", \"date\"\n",
    "    \n",
    "    indices = np.empty(len(final_array), dtype=object)\n",
    "    for i in range(len(final_array)):\n",
    "        indices[i] = str(final_array[i, 0]) + \", \" + str(final_array[i, 1]) + \", \" + str(final_array[i, 7])\n",
    "\n",
    "    print(indices)\n",
    "    selected_data1 = np.delete(final_array, [0, 1, 2, 7], 1)  # deleting locations\n",
    "    \n",
    "    if normalize_data:            \n",
    "        data = normalize(selected_data1, axis=0, norm='l2')\n",
    "    else:\n",
    "        data = selected_data1.copy()\n",
    "else:\n",
    "    data = final_array.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = kmapper.KeplerMapper()\n",
    "lens = km.project(data)\n",
    "graph = km.map(X=data, lens=lens, cover=kmapper.Cover(n_cubes=100, perc_overlap=0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx_graph = kmapper.adapter.to_nx(graph)\n",
    "\n",
    "\n",
    "url = 'make_circles_keplermapper_output.html'\n",
    "\n",
    "\n",
    "km.visualize(graph,\n",
    "                 path_html=url,\n",
    "                 title=\"COVID-19 Dataset\", custom_tooltips = indices)\n",
    "\n",
    "iframe = '<iframe src=' + url + ' width=1000 height=800></iframe>'\n",
    "IPython.display.HTML(iframe)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# #matplotlib.use('TKAgg',warn=False, force=True)\n",
    "# kmapper.draw_matplotlib(graph)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.08470888e-03 -1.58176329e-03  5.15756900e-03  1.09011520e-03]\n",
      " [ 2.08334826e-03 -1.57359252e-03  1.01505916e-03  1.09011520e-03]\n",
      " [ 2.10493406e-03 -1.57718489e-03  1.00063463e-03  1.09011520e-03]\n",
      " ...\n",
      " [ 1.38077424e-03 -2.12058977e-03  1.65614915e-05  2.70711942e-03]\n",
      " [ 1.47612440e-03 -2.13321959e-03  6.94514160e-06  2.70711942e-03]\n",
      " [ 2.30007398e-03 -2.17395400e-03  1.06848332e-06  2.70711942e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
